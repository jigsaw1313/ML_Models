# -*- coding: utf-8 -*-
"""Maven_Roaster_LinearRegressionModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ECpzEEjK3rp3ufngVls2-uVRT_M7sUa

# Load Libraries
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import numpy as np

"""# Load Dataset"""


df = pd.read_csv("<DATA_SET_PATH>")

"""# Processing the Data"""

# Choosing required features and them to new datafram
df_model = df[['transaction_qty', 'unit_price', 'product_category', 'transaction_day', 'store_location', 'total_sales']]

df_model.head()

"""## Convert Categorical Features to Numeric Features"""

# Mapping `product_category' to total_sales mean of each prodcut_category
category_means = df_model.groupby('product_category')['total_sales'].mean()
df_model['product_category'] = df_model['product_category'].map(category_means)

# Define the mapping dictionary
location_mapping = {'Hell\'s Kitchen': 1, 'Astoria': 2, 'Lower Manhattan': 3}

# Map the values in the 'store_location' column using the mapping dictionary
df_model['store_location'] = df_model['store_location'].map(location_mapping)

df_model.info()

"""## Scaling Features

__For feature scaling i have tried to test RobustScaler and StandardScaler. As per results , it seems that RobustScaler would have better affects on data and therefore better predictions__
"""

from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
for col in df_model.columns:
  df_model[col] = scaler.fit_transform(df_model[[col]])

# from sklearn.preprocessing import StandardScaler
# scaler = StandardScaler()
# for col in df_model.columns:
#   df_model[col] = scaler.fit_transform(df_model[[col]])

df_model.head()

"""# Machine Learning Models

## 1. Linear Regression Model
"""

# Linear regression model

X = df_model[['transaction_qty', 'unit_price', 'product_category', 'transaction_day', 'store_location']]
y = df_model['total_sales']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error:", mse)
print("R-squared:", r2)

"""## 2.1 Linear Regression Model - Gradient Descent
__Within this cell we have wrote GD Regression From Scratch__
"""

class GradientDescentLinearRegression:
    def __init__(self, learning_rate=0.01, n_iterations=1000):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.theta = None
        self.intercept = None

    def fit(self, X, y):
        m, n = X.shape
        self.theta = np.zeros(n)
        self.intercept = 0

        for _ in range(self.n_iterations):
            y_pred = np.dot(X, self.theta) + self.intercept
            error = y_pred - y
            gradient = np.dot(X.T, error) / m
            intercept_gradient = np.mean(error)
            self.theta -= self.learning_rate * gradient
            self.intercept -= self.learning_rate * intercept_gradient

    def predict(self, X):
        return np.dot(X, self.theta) + self.intercept


# Selecting X and y
X = df_model[['transaction_qty', 'unit_price', 'product_category', 'transaction_day', 'store_location']]
y = df_model['total_sales']

# Spliting Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Prepare data
X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values

# Instantiate and train the model
gd_lr = GradientDescentLinearRegression(learning_rate=0.01, n_iterations=1000)
gd_lr.fit(X_train_np, y_train_np)

# Make predictions
y_pred_gd = gd_lr.predict(X_test_np)

# Evaluation metrics
mse_gd = mean_squared_error(y_test, y_pred_gd)
r2_gd = r2_score(y_test, y_pred_gd)

print("Mean Squared Error (Gradient Descent):", mse_gd)
print("R-squared (Gradient Descent):", r2_gd)

"""## 2.2 Linear Regression Model - Gradient Descent (Using SGDRegressor)"""

from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Create a pipeline with feature scaling (optional but recommended for gradient descent)
pipeline = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))

# Selection X and y
X = df_model[['transaction_qty', 'unit_price', 'product_category', 'transaction_day', 'store_location']]
y = df_model['total_sales']

# Spliting Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
pipeline.fit(X_train, y_train)

# Make predictions
y_pred_sgd = pipeline.predict(X_test)

# Evaluation metrics
mse_sgd = mean_squared_error(y_test, y_pred_sgd)
r2_sgd = r2_score(y_test, y_pred_sgd)

print("Mean Squared Error (SGDRegressor):", mse_sgd)
print("R-squared (SGDRegressor):", r2_sgd)

